{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')\n",
    "def get_all_strings_from_list(list):\n",
    "    strings = []\n",
    "\n",
    "    for obj in list:\n",
    "        if not isinstance(obj, str):\n",
    "            strings += get_all_strings_from_list(obj)\n",
    "        else:\n",
    "            strings.append(obj)\n",
    "\n",
    "    return strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into a list of strings\n",
    "def read_data(dataset):\n",
    "    data = []\n",
    "\n",
    "    for tablename in dataset:\n",
    "        table = dataset[tablename]\n",
    "\n",
    "        # get words from the what is under the keys [\"title\", \"pgTitle\", \"secondTitle\", \"caption\", \"data\"]\n",
    "        keys = [\"title\", \"pgTitle\", \"secondTitle\", \"caption\", \"data\"]\n",
    "\n",
    "        for key in keys:\n",
    "            # if table does not have key, skip this key\n",
    "            if not key in table:\n",
    "                continue\n",
    "\n",
    "            strings = table[key]\n",
    "\n",
    "            data += get_all_strings_from_list([strings])\n",
    "\n",
    "    # filter data\n",
    "    #print(data)\n",
    "    data = filter(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def filter(strings):\n",
    "    data = []\n",
    "\n",
    "\n",
    "    for string in strings:\n",
    "\n",
    "        # make every string lowercase\n",
    "        string = str.lower(string)\n",
    "\n",
    "\n",
    "        # filter out html tag span style\n",
    "        #string = re.sub(r'<span.*?/span>', '', string, re.DOTALL)\n",
    "        string = re.sub(r'<span style.*?/span>', '', string)\n",
    "        string = re.sub(r'<.*?>','', string)\n",
    "\n",
    "        # filter out url\n",
    "        string = re.sub(r'(?P<url>https?://[^\\s]+)', '', string)\n",
    "\n",
    "        # remove whitespace on the sides\n",
    "        string = str.strip(string)\n",
    "\n",
    "        # skip empty words\n",
    "        if string == '':\n",
    "            continue\n",
    "\n",
    "        # skip words that only contain numbers\n",
    "\n",
    "        if re.match(r'^[0-9]+$', string):\n",
    "            continue\n",
    "\n",
    "        # replace symbols with a space\n",
    "        string = re.sub(r'[^a-z\\.]+', ' ', string)\n",
    "\n",
    "        # remove whitespace on the sides again\n",
    "        # (the symbol replacement might have added spaces on the sides)\n",
    "        string = str.strip(string)\n",
    "        # skip useless strings\n",
    "        if string == '' or string == '.' or string == 'none' or len(string)<3 or string in stops:\n",
    "            continue\n",
    "\n",
    "        # split on whitespace\n",
    "        words = string.split(' ')\n",
    "        data += words\n",
    "\n",
    "    return data\n",
    "\n",
    "#data = []\n",
    "index=0\n",
    "for filename in sorted(glob.glob('/Users/InSung/Desktop/tensor-flow/tables_redi2_1/re_tables_0007.json')):\n",
    "    index += 1\n",
    "    print('---','Processing ' + filename + '...')\n",
    "    input = json.load(open(filename))\n",
    "\n",
    "    #print(input)\n",
    "    input_data = read_data(input)\n",
    "    #data += input_data\n",
    "    data = filter(input_data)\n",
    "    #print(data)\n",
    "    with open('/Users/InSung/repos/msc-thesis-li-deng/parsed_words/%i.txt' %index, 'w') as f:\n",
    "        #print(data)\n",
    "        print(len(data))\n",
    "\n",
    "        data = ' '.join(data)\n",
    "\n",
    "        f.write(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
